{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "article_qualitative _data_regressions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMeWL9UPJuFOUKlB6d4FFUq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmangokturk/Qualitative-variables-in-regression/blob/main/article_qualitative__data_regressions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_dmeVq_HFqV"
      },
      "source": [
        "#refer to https://colab.research.google.com/drive/1QpEzZED0jhRhMu1P4C2tp6UGmY6h-Liu#scrollTo=jRS1pzCW5bAN\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diUX6XBRBLYY"
      },
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set_style(\"dark\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM5qlnlvHJC0"
      },
      "source": [
        "#DATA SETS\n",
        "#Credit LOAN data: \n",
        "url1 = 'https://raw.githubusercontent.com/michalis0/Business-Intelligence-and-Analytics/master/data/new_application_train_1.csv'\n",
        "df=pd.read_csv(url1)\n",
        "\n",
        "#LOAN DATA for REgression Asignment 2: https://colab.research.google.com/drive/1YLI3yQmOeW6dMbwIsWJ68grH0R21JKHt#scrollTo=ihAuQmYgwk1w\n",
        "url2 = \"https://raw.githubusercontent.com/michalis0/Business-Intelligence-and-Analytics/master/data/Credit.csv\"\n",
        "credits = pd.read_csv(url2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXpS2YbhJJP8"
      },
      "source": [
        "#MALE FEMALE, YES NOT ---integers for regression\n",
        "credits.replace(to_replace=['Female', ' Male'], value=[0, 1], inplace=True)\n",
        "credits.replace(to_replace=['No', 'Yes'], value=[0, 1], inplace=True)\n",
        "\n",
        "#NAn values\n",
        "df['column'] = df['column'].fillna(value) #pandas\n",
        "df['column'] = df['column'].replace(np.nan,value)\n",
        "#Entire df\n",
        "df.fillna(value)\n",
        "df.replace(np.nan, value)\n",
        "\n",
        "#Multipble columns, question to replace zeros with nan\n",
        "cols = [\"Weight\",\"Height\",\"BootSize\",\"SuitSize\",\"Type\"]\n",
        "df2[cols] = df2[cols].replace(['0', 0], np.nan)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MJNFxvqwbj3"
      },
      "source": [
        "#DATA MATRICES:  \n",
        "X=credits[['Age']]\n",
        "y=credits[['Rating']]\n",
        "\n",
        "\n",
        "# One-hot encoding\n",
        "#From the credits dataset, do 1-hot encoding on the column Ethnicity using the function get_dummies() from pandas\n",
        "eths=pd.get_dummies(credits.Ethnicity) # drop first=false would give us \"n variables\" while True would give us n-1 vars.#matrix can be used as well. \n",
        "\n",
        "\n",
        "# One-hot encoding #one var with n dif values  becomes n var \n",
        "Myone_hot = OneHotEncoder()  #call the fucnt\n",
        "cat_to_onehot = Myone_hot.fit_transform(df[[\"Group\"]]).toarray() #these two last lines can be combined.\n",
        "cat_to_onehot = pd.DataFrame(cat_to_onehot, columns=one_hot.categories_)\n",
        "\n",
        "\n",
        "# Label encoding # a colm (variable) with n difr values is still one collumn, this time values are replaced like 0-1-2-3-4...YES starting from 0\n",
        "myLabEn = LabelEncoder()\n",
        "cat_to_label = pd.Series(myLabEn.fit_transform(df[\"Group\"])) # for DF: df_encoded = df.apply(myLabEn.fit_transform)\n",
        "cat_to_label\n",
        "myLabEn.classes_ # to give us old categories. this is for one column. for DF, need to search\n",
        "#df.replace(to_replace=['<=50K', '>50K'], value=[0, 1], inplace=True) is also a label encoding. \n",
        "\n",
        "\n",
        "#DIRECTLY ENCODİNG\n",
        "# Encode Country and City\n",
        "data[\"Country\"] = data.Country.astype('category').cat.codes\n",
        "data[\"City\"] = data.City.astype('category').cat.codes\n",
        "\n",
        "#matrix or DB concatenation\n",
        "#X=pd.concat([X1,eths], axis=1, sort=False) # to estbal\n",
        "\n",
        "#Splitting train and Test\n",
        "#DATA SPLİT\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vyy_1CwmxiBW"
      },
      "source": [
        "#TRANSFORMATIONS:  örnek: poly tansformation. \n",
        "#önce model çağrılır. \n",
        "# X_poly =fit_transform(X) yapılarak yeni bir X_poly datası\n",
        "#sonra model.fit(X_poly, y) ile regression yapılıp, params elde edilir. #y burda devreye giriyor. öncesinde yok.\n",
        "\n",
        "#Polinomial transform: \n",
        "#Polynomial combination of features: 2 means square.\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "Mypoly = PolynomialFeatures(2)\n",
        "X_poly=Mypoly.fit_transform(X) # X 'lere bakmış oluyor. henüz y yok.  # function fit transform comes from package\n",
        "\n",
        "\n",
        "#Transform Fitting: min-manx\n",
        "#Define scale \n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit_transform(X_train, y_train) #I guess no need to include y here.\n",
        "#Apply normalization\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "####\n",
        "\n",
        "#Standardization, is helpful to give the same weight (or importance) \n",
        "# Standardize features #Standardize only the numerical features (not the categorical features) to have mean zero and standard deviation equal to 1.\n",
        "myStand = StandardScaler()\n",
        "myStand.fit(X_train, y_train) #here is fit, not fit_transform. #I think no need to put y here\n",
        "# !!!IMPORTANT: we must fit on the training set, not on the whole set!!!\n",
        "#https://stackoverflow.com/questions/23838056/what-is-the-difference-between-transform-and-fit-transform-in-sklearn\n",
        "#Burda anlatıldığına göre fit ve fit-transform biraz yakın birbirine. Ancak fit olayında sadece train olur.  transform ikisine de uygulanabilir.\n",
        "#bu stack.. link çok dolu gerçekten. bir X datasının transformasyonunda da mü ve sigma gibi parametrelerin bulunup sonra çeviriminin olması mevzusu vardır. \n",
        "X_train_s = myStand.transform(X_train)\n",
        "X_test_s = myStand.transform(X_test)\n",
        "X_train_s=pd.DataFrame(X_train_s, columns=X_train.columns)# se inside columns= oldXtrain.columns\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-Ouw5SfAxF9"
      },
      "source": [
        "#REGRESSION FITTING :\n",
        "examples:\n",
        "# LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000),\n",
        "#LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
        "\n",
        "#Mymodel.fit(X,y)# # regressionun ta kendisi. params ve r2 gelir. \n",
        "#LR.fit(X_tranin, y_train) ile fit yapıldıktan sonra Xtrain , yy train ve X test -ytest için MSE hesaplanabilir ayrıca\n",
        "\n",
        "#model çağrılır. X ve y ( veya X train, y train ) (vEYAHUT X sadece trasnform için--ama bununki fit_transform)\n",
        "LR = LinearRegression(fit_intercept=False)\n",
        "LR.fit(X_train, y_train) # 2 ci olarak  fit (train-train) edilir. \n",
        "\n",
        "\n",
        "#Create Model : train-split olayından farklı. önce bunu yaparsın. arguman olarak farklı şeyler vererbilirsin\n",
        "Mymodel=LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
        "\n",
        "#Model prediction from X_test\n",
        "predictions = Mymodel.predict(X_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nStssY4kiN__"
      },
      "source": [
        "REGRESSION PARAMS\n",
        "#LR=Mymodel = LinearRegression(fit_intercept=True), #LR.fit(X,y)\n",
        "#coef, intercept, score, predict önceden tanımlı.\n",
        "print(\"slope: \", LR.coef_[0])\n",
        "print(\"constant: \", LR.intercept_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1bNU5dYht1W"
      },
      "source": [
        "#REGRESSION METRICS: score, precission_score, recall_score, f1_score, confusion_matrix, \n",
        "#train-siplit ayrımı  şart değil. hangi argumanı verirsen ona göre olur. modeli hangi data üzerinde fit ettiğin önemli.\n",
        "#MSE ytest ve ypred arasındaki ilişkidir, yani X-test e bağlı. yani MSE test datasıyla oluşturulur.\n",
        "#\n",
        "\n",
        "# Compare the MAE the MSE and the R^2 \n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions) #LR.score(X,y) de olabilir çoklu X için. \n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(y, LR.predict(X)) #LR is the name, you can call it Mymodel\n",
        "#MSE train-test ile alakalı değildir. bu yüzden her ikisi için de ayrı ayrı yapılabilir. aşağıdaki örnekte olduğu gibi\n",
        "\n",
        "#To see the general improvement over models\n",
        "train_err.append(mean_squared_error(y_train, LR.predict(X_train)))\n",
        "test_err.append(mean_squared_error(y_test, LR.predict(X_test)))\n",
        "\n",
        "#MSE adn R2 are not the same, but related. R2=1-MSE/var(y): yani var(y) bağlı.Ayrıca MSE 0 iken R2 1, perfect. onun dışında açık değil ilişki.\n",
        "#MSE hata karleri toplamı/N. \n",
        "#R2 ise is mean çizgisiyle bir kıyaslama yapar. 1-RSS/TSS\n",
        "\n",
        "#ayrıca MSE y ve yhatleri kıyaslarken, R2 y-ybar ve yhat-ybar kıyaslamalaryıla gider.\n",
        "#more info:https://vitalflux.com/mean-square-error-r-squared-which-one-to-use/\n",
        "\n",
        "# Accuracy of training set\n",
        "myModel.score(X_train, y_train)\n",
        "#of test st\n",
        "myModel.score(X_test, y_test) #or  accuracy_score(myModel.predict(X_test), y_test)\n",
        "\n",
        "#confusion matrix\n",
        "confusion_matrix(y_test, log_reg.predict(X_test)) # func(yTest,yPred)\n",
        "\n",
        "#TOPLU BAKIŞ. sonra evaluate(y_test, y_pred) diye argumantasyon yapınca olur. (ikili class?)\n",
        "def evaluate(true, pred):\n",
        "    precision = precision_score(true, pred)\n",
        "    recall = recall_score(true, pred)\n",
        "    f1 = f1_score(true, pred)\n",
        "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(true, pred)}\")\n",
        "    print(f\"ACCURACY SCORE:\\n{accuracy_score(true, pred):.4f}\")\n",
        "    print(f\"CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "evaluate(y_test, y_pred) #will produce a) 2 by 2 confus matrix.b) acuracy score, c) classification repport\n",
        "\n",
        "#print other infor: True negatives.....\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "print(\"True positives: \" + str(tp))\n",
        "print(\"True negatives: \" + str(tn))\n",
        "print(\"False positives: \" + str(fp))\n",
        "print(\"False negatives: \" + str(fn))\n",
        "\n",
        "\n",
        "#ikili confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_true = np.array([[0,0,1], [1,1,0],[0,1,0]])\n",
        "y_pred = np.array([[0,0,1], [1,0,1],[1,0,0]])\n",
        "\n",
        "labels = [\"A\", \"B\", \"C\"]\n",
        "\n",
        "conf_mat_dict={}\n",
        "\n",
        "for label_col in range(len(labels)):\n",
        "    y_true_label = y_true[:, label_col]\n",
        "    y_pred_label = y_pred[:, label_col]\n",
        "    conf_mat_dict[labels[label_col]] = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
        "\n",
        "\n",
        "for label, matrix in conf_mat_dict.items():\n",
        "    print(\"Confusion matrix for label {}:\".format(label))\n",
        "    print(matrix)\n",
        "#or from package\n",
        "import sklearn.metrics as skm\n",
        "cm = skm.multilabel_confusion_matrix(y_true, y_pred)\n",
        "print(cm)\n",
        "print(skm.classification_report(y_true,y_pred))\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPaUUWIx2ZcA"
      },
      "source": [
        "#örnek. yukarıdan\n",
        "#polynom formatlarını karşılaştıracak her bir degree için train ve testin MSE ayrı ayrı hesaplayıp grafikte gösterecek.\n",
        "\n",
        "train_err = []\n",
        "test_err = []\n",
        "# X = X[:,0].reshape(-1,1)\n",
        "for f in range(1,7):\n",
        "    poly = PolynomialFeatures(f)\n",
        "    X_poly = poly.fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=10)\n",
        "    LR = LinearRegression(fit_intercept=False)\n",
        "    LR.fit(X_train, y_train)\n",
        "    train_err.append(mean_squared_error(y_train, LR.predict(X_train)))\n",
        "    test_err.append(mean_squared_error(y_test, LR.predict(X_test)))\n",
        "plt.plot(range(1,7), train_err, label=\"train_error\")\n",
        "plt.plot(range(1,7), test_err, label=\"test_error\")\n",
        "plt.legend(fontsize=10)\n",
        "plt.xlabel(\"polynomial degree\")\n",
        "plt.ylabel(\"error\")\n",
        "# plt.ylim([0, 100]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb0swYLjK1-6"
      },
      "source": [
        "#PREDICTION\n",
        "ypred=myModel.predict(X_test )\n",
        "myModel.predict_proba(X_test) #0,1,2 kategorileri için toplamları 1 olan 3 tane olasılık hesaplayacak. hangisi büyükse kategori o olacaktır.\n",
        "#predictions ( tanımlı zaten) ==== Mymodel.predict(X) ( bölünmüş olsaydı, X_test kullanırdık.)\n",
        "\n",
        "#predict the Sales of a product with 200 TV advertisments: X value \n",
        "Mymodel.predict(np.array(200).reshape(-1, 1))\n",
        "\n",
        "#Çoklu X prediction\n",
        "print(\"TV, 200, Radi 50 için neolur?: \", 200, \"Radio: \", 50, \"Sales: \", LR.predict(np.array([200, 50]).reshape(-1,2)))\n",
        "\n",
        "\n",
        "#check 5the Row, before split.\n",
        "print(\" x5:\", X.iloc[[4]])\n",
        "print(\"y5:\",y.iloc[[4]])\n",
        "\n",
        "\n",
        "fifthRowPredict=model.predict(X.iloc[[4]].round(0))\n",
        "print(\"predicted y5: \", fifthRowPredict)\n",
        "\n",
        "# absolute error from the true age:\n",
        "print(\" absolute error from the true age:\", abs(y.iloc[[4]].values-fifthRowPredict).round(0))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VG_ilUvMJTd"
      },
      "source": [
        "#MULTI CLASS, METRİCS\n",
        "#acuraccy is always one element.\n",
        "confusion_matrix(y_test, mymodel.predict(X_test)) # no difference gibi görünüyor.  3x3 matrix çıkmış.\n",
        "\n",
        "#Thıs Exkample:\n",
        "y_true = np.array([[0,0,1], [1,1,0],[0,1,0]])\n",
        "y_pred = np.array([[0,0,1], [1,0,1],[1,0,0]])\n",
        "\n",
        "####\n",
        "labels = [\"A\", \"B\", \"C\"]\n",
        "\n",
        "conf_mat_dict={}\n",
        "\n",
        "for label_col in range(len(labels)):\n",
        "    y_true_label = y_true[:, label_col]\n",
        "    y_pred_label = y_pred[:, label_col]\n",
        "    conf_mat_dict[labels[label_col]] = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
        "\n",
        "\n",
        "for label, matrix in conf_mat_dict.items():\n",
        "    print(\"Confusion matrix for label {}:\".format(label))\n",
        "    print(matrix)\n",
        "\n",
        "# Or with \n",
        "import sklearn.metrics as skm\n",
        "cm = skm.multilabel_confusion_matrix(y_true, y_pred)\n",
        "print(cm)\n",
        "print(skm.classification_report(y_true,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBZ-yyB1MJIo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehTC_VOLK2Ip"
      },
      "source": [
        "\n",
        "#LEAS SQUARE METHOD\n",
        "slope = (np.inner(X, y) - sum(X)*sum(y) / n) / (sum(X**2) - sum(X)**2 / n)\n",
        "constant = np.mean(y) - slope * np.mean(X)\n",
        "print(\"slope: \", slope, \"constant: \", constant)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqJxKWVnfjOT"
      },
      "source": [
        "#CLASSIFICATION, \n",
        "\n",
        "# Base rate, for 2 categories\n",
        "max(len(df[df[\"target\"] == 0]) / len(df), len(df[df[\"target\"] == 1]) / len(df))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvKXQjKBfjAr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnYGeg4m3eew"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d8_QqIJK2RT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "93f9c2bd-ba06-4de9-e017-e5e067c40dcf"
      },
      "source": [
        "#LAMBDA \n",
        "#4 keyarea: name lambda, param, :, and  returun ( only one return, i.e.,expression)\n",
        "#instead of def, lamda\n",
        "#result is functin object whic is assigned to its identifier (doubler) \n",
        "doubler = lambda a: a * 2\n",
        "y = lambda a, b : a * b\n",
        "print(doubler(5)) #like add multiply by2  its arguement\n",
        "#x is like function name, a, b like parameters. after the : is returun.\n",
        "\n",
        "#one usage: \n",
        "def myfunc(n):\n",
        "  return lambda c : c * n\n",
        "\n",
        "mydoubler = myfunc(2)\n",
        "print(mydoubler(11))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QITSwPRlK2Y7"
      },
      "source": [
        "my_list = [1, 5, 4, 6, 8, 11, 3, 12]\n",
        "\n",
        "new_list = list(filter(lambda x: (x%2 == 0) , my_list))\n",
        "\n",
        "print(new_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoj3M-XOSl7v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqKSEDd3Slt_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}